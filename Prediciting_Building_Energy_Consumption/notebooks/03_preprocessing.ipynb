{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0245333",
   "metadata": {},
   "source": [
    "# 3 Preprocessing<a id='3_Preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1189ba",
   "metadata": {},
   "source": [
    "## 3.1 Contents<a id='3.1_Contents'></a>\n",
    "* [3 Preprocessing](#3_Preprocessing)\n",
    "  * [3.1 Contents](#3.1_Contents)\n",
    "  * [3.2 Introduction](#3.2_Introduction)\n",
    "    * [3.2.1 Recap of Data Science Problem](#3.2.1_Recap_of_Data_Science_Problem)\n",
    "    * [3.2.2 Introduction To Notebook](#3.2.2_Introduction_To_Notebook)\n",
    "  * [3.3 Objectives](#3.3_Objectives)\n",
    "  * [3.4 Imports](#3.4_Imports)\n",
    "  * [3.5 Load Data](#3.5_Load_Data)\n",
    "  * [3.6 Filling in missing values with moving average](#3.6_Filling_in_missing_values_with_moving_average)\n",
    "  * [3.7 Merge building data with processed weather data](#3.7_Merge_building_data_with_processed_weather_data)\n",
    "  * [3.8 Add additional features](#3.8_Add_additional_features)\n",
    "  * [3.9 Set aside validation data](#3.9_Set_aside_validation_data)\n",
    "  * [3.10 Split data into training and testing data](#3.10_Split_data_into_training_and_testing_data)\n",
    "    * [3.10.1 Subsample the data for linear regression and random forest models](#3.10.1_Subsample_the_data_for_linear_regression_and_random_forest_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8008bc3",
   "metadata": {},
   "source": [
    "## 3.2 Introduction<a id='3.2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5fb74",
   "metadata": {},
   "source": [
    "### 3.2.1 Recap of Data Science Problem<a id='3.2.1_Recap_of_Data_Science_Problem'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7ca15",
   "metadata": {},
   "source": [
    "The goal of this project is to predict the building energy consumption baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c5c52",
   "metadata": {},
   "source": [
    "### 3.2.2 Introduction To Notebook<a id='3.2.2_Introduction_To_Notebook'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7952ad",
   "metadata": {},
   "source": [
    "The datasets are the following:\n",
    "* meter readings with energy use in kWh per hour for the year 2016. This dataset contains the building ID, the meter type (e.g., chilled water, electricity, steam, and hot water), and the meter reading.\n",
    "* Details about each building. This includes the primary use of the building (e.g., education, office, etc.), number of floors, square footage, year it was built, and a site ID that links to weather data\n",
    "* Weather data. This includes precipitation, cloud coverage, air temperature, dew temperature, sea level pressure, and wind direction and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989f65c",
   "metadata": {},
   "source": [
    "## 3.3 Objectives<a id='3.3_Objectives'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab0e58",
   "metadata": {},
   "source": [
    "* Fill in missing values in weather data with the moving average of the weather features over time\n",
    "* Add additional features such as day of the week, month, hour, and season, and convert these to cyclic features\n",
    "* Set aside validation data to test the final model with\n",
    "* Split the data into training and testing data\n",
    "* Obtain subsamples from the training and testing sets to use for the linear and random forest regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7f97e",
   "metadata": {},
   "source": [
    "## 3.4 Imports<a id='3.4_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas, matplotlib.pyplot, and seaborn in the correct lines below\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import dates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd2257",
   "metadata": {},
   "source": [
    "## 3.5 Load Data<a id='3.5_Load_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed9d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the supplied CSV data files are in the data/processed directory\n",
    "#load data\n",
    "weather_data=pd.read_csv('../data/processed/weather_data_clean.csv')\n",
    "building_and_meter_data=pd.read_csv('../data/processed/building_and_meter_data.csv')\n",
    "\n",
    "# drop unnecessary columns\n",
    "building_and_meter_data=building_and_meter_data.drop('Unnamed: 0',axis=1)\n",
    "weather_data=weather_data.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "#add kWh/square_feet column\n",
    "building_and_meter_data['consumption_per_square_feet']=building_and_meter_data['meter_reading']/building_and_meter_data['square_feet']\n",
    "\n",
    "# change the format of timestamp to datetime\n",
    "building_and_meter_data['timestamp']=pd.to_datetime(building_and_meter_data['timestamp'],format='%Y-%m-%d %H:%M:%S')\n",
    "weather_data['timestamp']=pd.to_datetime(weather_data['timestamp'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23f12a",
   "metadata": {},
   "source": [
    "select electricity meter readings only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9dbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_meter=(building_and_meter_data['meter']==0)\n",
    "electricity_data=building_and_meter_data[by_meter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a76d1",
   "metadata": {},
   "source": [
    "## 3.6 Filling in missing values with moving average<a id='3.6_Filling_in_missing_values_with_moving_average'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8710cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids=weather_data.site_id.unique()\n",
    "weather_features=weather_data.columns[2:9]\n",
    "for site_id in site_ids:\n",
    "    by_site_id=(weather_data['site_id']==site_id)\n",
    "    weather_by_site_id=weather_data[by_site_id]\n",
    "    for feature in weather_features:\n",
    "        weather_data.loc[weather_data['site_id']==site_id,feature]=weather_by_site_id[feature].interpolate('index').rolling(168).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a939ac8",
   "metadata": {},
   "source": [
    "Drop unnecessary colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b97111",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data=weather_data.drop(['precip_depth_1_hr_log','cloud_coverage_log','wind_speed_log'],axis=1)\n",
    "electricity_data=electricity_data.drop(['meter_reading_log','floor_count_log','square_feet_log'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffbb0a",
   "metadata": {},
   "source": [
    "## 3.7 Merge building data with processed weather data<a id='3.7_Merge_building_data_with_processed_weather_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67f9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=electricity_data.merge(weather_data, on=['timestamp','site_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa354f6",
   "metadata": {},
   "source": [
    "## 3.8 Add additional features<a id='3.8_Add_additional_features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408a6bb",
   "metadata": {},
   "source": [
    "Here, I am going to do some more feature engineering. I am adding season as a feature, and cyclic features for the month, day, and hour features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca61782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {3:(datetime.datetime(2016,6,21), datetime.datetime(2016,9,22)),\n",
    "           4:(datetime.datetime(2016,9,23), datetime.datetime(2016,12,20)),\n",
    "           2:(datetime.datetime(2016,3,21), datetime.datetime(2016,6,20))}\n",
    "\n",
    "def get_season(date):\n",
    "    for season,(season_start, season_end) in seasons.items():\n",
    "        if date>=season_start and date<= season_end:\n",
    "            return season\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d15f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['season']=data['timestamp'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae7c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cos_hour\"] = np.cos(2 * math.pi * data[\"hour\"] / data[\"hour\"].max())\n",
    "data[\"sin_hour\"] = np.sin(2 * math.pi * data[\"hour\"] / data[\"hour\"].max())\n",
    "data[\"cos_month\"] = np.cos(2 * math.pi * data[\"month\"] / data[\"month\"].max())\n",
    "data[\"sin_month\"] = np.sin(2 * math.pi * data[\"month\"] / data[\"month\"].max())\n",
    "data[\"cos_day\"] = np.cos(2 * math.pi * data[\"day\"] / data[\"day\"].max())\n",
    "data[\"sin_day\"] = np.sin(2 * math.pi * data[\"day\"] / data[\"day\"].max())\n",
    "data[\"cos_dayofweek\"] = np.cos(2 * math.pi * data[\"dayofweek\"] / data[\"dayofweek\"].max())\n",
    "data[\"sin_dayofweek\"] = np.sin(2 * math.pi * data[\"dayofweek\"] / data[\"dayofweek\"].max())\n",
    "data[\"cos_season\"] = np.cos(2 * math.pi * data[\"season\"] / data[\"season\"].max())\n",
    "data[\"sin_season\"] = np.sin(2 * math.pi * data[\"season\"] / data[\"season\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3817097",
   "metadata": {},
   "source": [
    "## 3.9 Set aside validation data<a id='3.9_Set_aside_validation_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a84cce",
   "metadata": {},
   "source": [
    "Here I want to set aside meter readings from buildings 1298 and 283 to validate the final chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e5b97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring aside building 1298 for validation\n",
    "validation_data=data[data['building_id']==1298]\n",
    "validation_data.to_csv('../data/processed/electricity/validation_data.csv')\n",
    "data=data[data['building_id']!=1298]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a33b9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring aside building 1298 for validation\n",
    "validation_data=data[data['building_id']==283]\n",
    "validation_data.to_csv('../data/processed/electricity/validation_data_283.csv')\n",
    "#data=data[data['building_id']!=1298]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e444c",
   "metadata": {},
   "source": [
    "## 3.10 Split data into training and testing data<a id='3.10_Split_data_into_training_and_testing_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ed622",
   "metadata": {},
   "source": [
    "Because I have a large dataset, here I am taking subsamples of 10,000 and 100,000 rows from the large dataset to use these subsamples for training the linear and random forest regression models. But before doing so, I am splitting the data into training and testing data, then taking the subsamples from the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6436492",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns='meter_reading')\n",
    "y=data.meter_reading\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007c098",
   "metadata": {},
   "source": [
    "### 3.10.1 Subsample the data for linear regression and random forest models<a id='3.10.1_Subsample_the_data_for_linear_regression_and_random_forest_models'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "420801ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample_lr=X_train.sample(100000,random_state=123)\n",
    "X_test_subsample_lr=X_test.sample(100000,random_state=123)\n",
    "y_train_subsample_lr=y_train.sample(100000,random_state=123)\n",
    "y_test_subsample_lr=y_test.sample(100000,random_state=123)\n",
    "\n",
    "X_train_subsample_rf=X_train.sample(10000,random_state=123)\n",
    "X_test_subsample_rf=X_test.sample(10000,random_state=123)\n",
    "y_train_subsample_rf=y_train.sample(10000,random_state=123)\n",
    "y_test_subsample_rf=y_test.sample(10000,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b3e22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample_lr.to_csv('../data/processed/electricity/subsamples/linear/X_train_subsample_lr.csv')\n",
    "X_test_subsample_lr.to_csv('../data/processed/electricity/subsamples/linear/X_test_subsample_lr.csv')\n",
    "y_train_subsample_lr.to_csv('../data/processed/electricity/subsamples/linear/y_train_subsample_lr.csv')\n",
    "y_test_subsample_lr.to_csv('../data/processed/electricity/subsamples/linear/y_test_subsample_lr.csv')\n",
    "\n",
    "X_train_subsample_rf.to_csv('../data/processed/electricity/subsamples/random_forest/X_train_subsample_rf.csv')\n",
    "X_test_subsample_rf.to_csv('../data/processed/electricity/subsamples/random_forest/X_test_subsample_rf.csv')\n",
    "y_train_subsample_rf.to_csv('../data/processed/electricity/subsamples/random_forest/y_train_subsample_rf.csv')\n",
    "y_test_subsample_rf.to_csv('../data/processed/electricity/subsamples/random_forest/y_test_subsample_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f0016ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/processed/electricity/X_train.csv')\n",
    "X_test.to_csv('../data/processed/electricity/X_test.csv')\n",
    "y_train.to_csv('../data/processed/electricity/y_train.csv')\n",
    "y_test.to_csv('../data/processed/electricity/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b13a847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/electricity/elec_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "building_energy_project",
   "language": "python",
   "name": "building_energy_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
